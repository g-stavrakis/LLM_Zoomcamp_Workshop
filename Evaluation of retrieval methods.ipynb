{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d599c7c-f3de-4d32-a7ac-030a06b77deb",
   "metadata": {},
   "source": [
    "# Evaluation of retrieval methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d893f69-b4b4-4933-9484-bb933f2ad0b9",
   "metadata": {},
   "source": [
    "## Create the Ground truth dataset for retrieval evaluation\n",
    "\n",
    "Ground truth is the dataset that contains all the relevant documents that should be retrieved from each query. Consider this as a label dataset that we know in advance the correct documents we need to retrieve for each query.\n",
    "\n",
    "You can create a ground truth in various ways:\n",
    "- Human annotators: That will find and label manually all the relevant documents for each query\n",
    "- User interaction annotators: In production system people or LLMs can examine user queries and system results and label the most relevant docs\n",
    "- LLM synthetic data: Use an LLM to generate a number of synthetic user questions for each record/document that we want to retrieve\n",
    "\n",
    "In this exercise, the last option will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b154058-9e64-4751-8333-aa7abc329554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .envrc \n",
    "load_dotenv(\".envrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43512c9-18ae-48c1-a8f2-a5008a5896bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the documents that we want to fetch\n",
    "import requests\n",
    "# To get the documents I will download them for the GitHub repo\n",
    "url_path = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json'\n",
    "response = requests.get(url_path)\n",
    "# Read the Json file \n",
    "docs_raw = response.json()\n",
    "# Flatten the json (add the course in each question)\n",
    "documents = []\n",
    "# For each course in the Json\n",
    "for courses in docs_raw:\n",
    "    # Add the course name to the document\n",
    "    for doc in courses['documents']:\n",
    "        doc['course'] = courses['course']\n",
    "        documents.append(doc)\n",
    "# See the first question of the document\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdf13f-591c-406e-93b2-0027d4f3904b",
   "metadata": {},
   "source": [
    "### Create an unique identifier for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5ea92f-9d8d-498b-8f7b-73214063f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the library to create a hash key\n",
    "import hashlib\n",
    "\n",
    "# Create the function to generate the unique doc id\n",
    "def generate_document_id(doc):\n",
    "    # To create a unique string to hash we take the text from different elements of the document\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    # Create the hash object from the string\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    # Create a string from the hashed object\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    # Takne the first 8 digits of the string\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4e6993-6f1f-4a36-8dc1-6cb442515428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a unique id for each document\n",
    "for doc in documents:\n",
    "    doc['id'] = generate_document_id(doc)\n",
    "# Examine the first record\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719b590a-d428-4f0a-8e7f-d7c319bc4c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947 948\n",
      "593f7569 2\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "from collections import defaultdict\n",
    "hashes = defaultdict(list)\n",
    "for doc in documents:\n",
    "    doc_id = doc['id']\n",
    "    hashes[doc_id].append(doc)\n",
    "# See the length\n",
    "print(len(hashes), len(documents))\n",
    "# Find the duplicate entries\n",
    "for k, values in hashes.items():\n",
    "    if len(values) > 1:\n",
    "        print(k, len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8d485-fa7b-4dc7-9db1-055c8e5301f7",
   "metadata": {},
   "source": [
    "### Generate user questions for each record using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32077155-0745-401a-a4b9-688cae3db2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt template for the LLM\n",
    "prompt_template = \"\"\"\n",
    "You emulate a student who's taking our course.\n",
    "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974a58a3-0dfa-4dde-b02d-b6a0c188ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI instance\n",
    "from openai import OpenAI\n",
    "# Initialzite the client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7307991e-868f-4ce7-82d6-947d54bf905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"When is the exact start date and time of the course?\",\n",
      "    \"How can I subscribe to the course's public Google Calendar?\",\n",
      "    \"Where can I register before the course begins?\",\n",
      "    \"How do I join the course's Telegram channel for announcements?\",\n",
      "    \"Which Slack channel should I join after registering in DataTalks.Club?\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Generate questions from the first record\n",
    "sample = documents[0]\n",
    "# Create the prompt\n",
    "prompt = prompt_template.format(**sample)\n",
    "# Make the request\n",
    "full_response = client.chat.completions.create(\n",
    "    model = 'gpt-4o',\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}])\n",
    "# Parse the response\n",
    "response = full_response.choices[0].message.content\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee963da0-6c9c-43ce-bda5-5f1bfb1cb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to generate the questions\n",
    "def generate_questions(doc):\n",
    "    # Create the prompt from a template\n",
    "    prompt = prompt_template.format(**doc)\n",
    "    # Request from the model\n",
    "    full_response = client.chat.completions.create(\n",
    "        model = 'gpt-4o',\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}])\n",
    "    # Parse the response\n",
    "    response = full_response.choices[0].message.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff73be-b06f-4a4e-960e-a33a1fbaa609",
   "metadata": {},
   "source": [
    "### Create the ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07bce8dd-8cc3-4236-96c9-2e9488752b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the dataset to generate the questions\n",
    "docs = documents[:5]\n",
    "\n",
    "# Initialize the results object\n",
    "results = {}\n",
    "# For each document generate the user questions\n",
    "for doc in docs:\n",
    "    doc_id = doc['id']\n",
    "    results[doc_id] = generate_questions(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fc24515-0522-4cb7-93be-a6b8a751c1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c02e79ef</td>\n",
       "      <td>When will the course begin?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c02e79ef</td>\n",
       "      <td>How can I add the course schedule to my calendar?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c02e79ef</td>\n",
       "      <td>Where should I register before the course starts?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c02e79ef</td>\n",
       "      <td>Is there a Telegram channel for course announc...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c02e79ef</td>\n",
       "      <td>Should I join any specific Slack channels for ...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1f6520ca</td>\n",
       "      <td>What background knowledge do I need before enr...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1f6520ca</td>\n",
       "      <td>Are there any specific skills required to star...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1f6520ca</td>\n",
       "      <td>Where can I find the required prerequisites to...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1f6520ca</td>\n",
       "      <td>Is there a list of prerequisites available for...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1f6520ca</td>\n",
       "      <td>How can I check the prerequisites for this cou...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                           question  \\\n",
       "0  c02e79ef                        When will the course begin?   \n",
       "1  c02e79ef  How can I add the course schedule to my calendar?   \n",
       "2  c02e79ef  Where should I register before the course starts?   \n",
       "3  c02e79ef  Is there a Telegram channel for course announc...   \n",
       "4  c02e79ef  Should I join any specific Slack channels for ...   \n",
       "5  1f6520ca  What background knowledge do I need before enr...   \n",
       "6  1f6520ca  Are there any specific skills required to star...   \n",
       "7  1f6520ca  Where can I find the required prerequisites to...   \n",
       "8  1f6520ca  Is there a list of prerequisites available for...   \n",
       "9  1f6520ca  How can I check the prerequisites for this cou...   \n",
       "\n",
       "                      course  \n",
       "0  data-engineering-zoomcamp  \n",
       "1  data-engineering-zoomcamp  \n",
       "2  data-engineering-zoomcamp  \n",
       "3  data-engineering-zoomcamp  \n",
       "4  data-engineering-zoomcamp  \n",
       "5  data-engineering-zoomcamp  \n",
       "6  data-engineering-zoomcamp  \n",
       "7  data-engineering-zoomcamp  \n",
       "8  data-engineering-zoomcamp  \n",
       "9  data-engineering-zoomcamp  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "user_query = []\n",
    "course = []\n",
    "i = 0 \n",
    "\n",
    "for id, questions_string in results.items():\n",
    "    # Convert the string of questions to a list\n",
    "    questions = json.loads(questions_string)\n",
    "    for query in questions:\n",
    "        ids.append(id)\n",
    "        user_query.append(query)\n",
    "        course.append(docs[i]['course'])\n",
    "    i+=1\n",
    "# Create the dictionary to save as a dataframe\n",
    "results_dic = {'document':ids,'question': user_query, 'course':course}\n",
    "# Create the dataframe with the ground truth dataset\n",
    "df = pd.DataFrame(results_dic)\n",
    "# View the dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab4cf5-b39c-4d89-816a-da789191e56c",
   "metadata": {},
   "source": [
    "## Evaluate the different search methods \n",
    "\n",
    "To evaluate the different search methods that we have created for our RAG system we will compute and compare the below metrics:\n",
    "- **Hit Rate (HR) at k**: Counts from all the retrieval requests, how many of them contained the relevant documents in the top k results\n",
    "- **Mean Reciprocal Rank (MRR)**: Takes into account also the rank of the relevant document, with responses with the relevant document ranked higher with have a bigger score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef210906-1dc6-40ed-a02f-02c469d9acb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-19 05:36:58--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-vector-search/eval/ground-truth-data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 504747 (493K) [text/plain]\n",
      "Saving to: ‘ground-truth-data.csv.1’\n",
      "\n",
      "ground-truth-data.c 100%[===================>] 492.92K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-09-19 05:36:58 (12.0 MB/s) - ‘ground-truth-data.csv.1’ saved [504747/504747]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the full dataset with ground truth\n",
    "# !wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-vector-search/eval/ground-truth-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d11bd0-c731-48fe-8309-d5763af8d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When does the course begin?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can I get the course schedule?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the link for course registration?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I receive course announcements?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where do I join the Slack channel?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>c02e79ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where can I find the prerequisites for this co...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do I check the prerequisites for this course?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Where are the course prerequisites listed?</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What are the requirements for joining this cou...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Where is the list of prerequisites for the cou...</td>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>1f6520ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                        When does the course begin?   \n",
       "1                 How can I get the course schedule?   \n",
       "2          What is the link for course registration?   \n",
       "3            How can I receive course announcements?   \n",
       "4                 Where do I join the Slack channel?   \n",
       "5  Where can I find the prerequisites for this co...   \n",
       "6  How do I check the prerequisites for this course?   \n",
       "7         Where are the course prerequisites listed?   \n",
       "8  What are the requirements for joining this cou...   \n",
       "9  Where is the list of prerequisites for the cou...   \n",
       "\n",
       "                      course  document  \n",
       "0  data-engineering-zoomcamp  c02e79ef  \n",
       "1  data-engineering-zoomcamp  c02e79ef  \n",
       "2  data-engineering-zoomcamp  c02e79ef  \n",
       "3  data-engineering-zoomcamp  c02e79ef  \n",
       "4  data-engineering-zoomcamp  c02e79ef  \n",
       "5  data-engineering-zoomcamp  1f6520ca  \n",
       "6  data-engineering-zoomcamp  1f6520ca  \n",
       "7  data-engineering-zoomcamp  1f6520ca  \n",
       "8  data-engineering-zoomcamp  1f6520ca  \n",
       "9  data-engineering-zoomcamp  1f6520ca  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the full dataset with the ground truth\n",
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')\n",
    "df_ground_truth.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bdaa99-79cb-4226-aa6a-99a22cba30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'When does the course begin?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}, {'question': 'How can I get the course schedule?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}, {'question': 'What is the link for course registration?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}, {'question': 'How can I receive course announcements?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}, {'question': 'Where do I join the Slack channel?', 'course': 'data-engineering-zoomcamp', 'document': 'c02e79ef'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of records\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')\n",
    "print(ground_truth[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f9fb01-166e-44c4-8830-677ff2aa2cec",
   "metadata": {},
   "source": [
    "### Create the two metrics we will examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51900e5-4d14-4f9f-accf-5579933c2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the HR metric\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5ef0af-fc4f-4283-8099-e82d2fb2decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MRR metric\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4145d82f-c115-4152-8afc-73bae6f0e5e8",
   "metadata": {},
   "source": [
    "### Evaluate the elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb5fdca-cb54-46d1-aea5-30e733d93cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Elastic Search\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43da46ef-26c5-4bed-bd5b-a00aa6b06c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client \n",
    "es_client = Elasticsearch('http://localhost:9200') # This is the port created after running the docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ddc38c1-b01b-4d65-a614-00c4d7e72fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Schema of the Elastic Search Index\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"course-questions\"\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12ccaa0f-fd54-4dec-bfe1-341b7ba9ef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8286f8a7b17494889d52e3d3d82c5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the documents into the elastic search index\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41c7533d-0287-44de-9ef5-f1418d1fde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, course):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": course\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f472ac59-ea2f-4b9f-8139-fc9b50d1da28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e0207470c14589bbbce3802a0eaf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the ground truth queries to see if you can find the relevant documents\n",
    "relevance_total = []\n",
    "# Create a request for each query in ground truth\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    results = elastic_search(query=q['question'], course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43e8e519-eca9-4f45-bb99-d8ff43ce4712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7395720769397017, 0.6029788920106625)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the search method\n",
    "hit_rate(relevance_total), mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "189c46b5-198f-40de-a8dd-a3b92278a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate different search_functions\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c9271-cbee-4332-87b7-696f281fd5b3",
   "metadata": {},
   "source": [
    "## Evaluate vector search\n",
    "\n",
    "To evaluate the vector search we need to follow the following steps:\n",
    "- Initialize a transformer model to create embedding\n",
    "- Create the embeddings of the specific fields of the FAQ record\n",
    "- Adjust the Index settings in Elastic Search and index these embeddings\n",
    "- Create the embedding of the user query and query the data\n",
    "- Calculate the HR and MRR metrics comparing the retrieved data with the ground truth dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd3bb9-e8c1-422d-a2b6-3b7c57c6befa",
   "metadata": {},
   "source": [
    "### Initialize a transformer model to create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02382292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library to create the embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cacdb62c-805c-4d7d-8aa4-3fea54cc5659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the selected model to create the embeddings\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# Create an initial vector / embedding of the answer using the model\n",
    "res = model.encode(ground_truth[0]['question'])\n",
    "# Find the dimensionality of this vector\n",
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60726c-7b15-4cb7-a7b0-6aa797a0e374",
   "metadata": {},
   "source": [
    "### Create the embeddings of the specific fields of the FAQ record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb77f6f-6f40-443f-baa6-c95906f8f14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3227816fc69e4f77bafc11b8ea882409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the embeddings for each record in our FAQ dataset\n",
    "for doc in tqdm(documents):\n",
    "    # Extract the text fields you want to embed\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    question_text = doc['question'] + ' ' + doc['text']\n",
    "    \n",
    "    # Create the embedding for each text field\n",
    "    doc['question_vector'] = model.encode(question)\n",
    "    doc['text_vector'] = model.encode(text)\n",
    "    doc['question_text_vector'] = model.encode(question_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b69757-0e9c-4857-83ed-cb0260a0c43b",
   "metadata": {},
   "source": [
    "### Adjust the Index settings in Elastic Search and index these embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94800550-3c0c-4843-b569-4772b05bfa6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector_question'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Schema of the Elastic Search Index\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"vector_question\"\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "197a24d4-7c30-4cb7-9d85-7f4026c39190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e23a43133941668dd71a3f8cf4c385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Index the documents along with their vectors in the new index\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document = doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55825738-ac85-452a-b62c-c3e4d12b31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new elastic seach query for the vector search\n",
    "\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f070469-aa1f-4ddd-96da-2017babbd28b",
   "metadata": {},
   "source": [
    "### Create the embedding of the user query and query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b15f9863-b526-41be-8932-baef6949c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the search function to use for evaluation\n",
    "def question_vector_knn(user_query):\n",
    "    # Extract the text field\n",
    "    question = user_query['question']\n",
    "    # Extract keyword for filtering the results\n",
    "    course = user_query['course']\n",
    "    # Create the embedding of the user query\n",
    "    v_q = model.encode(question)\n",
    "    return elastic_search_knn('question_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45ebbfa4-20a8-4218-b8ea-68e545b04698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the search function to use for evaluation\n",
    "def text_vector_knn(user_query):\n",
    "    # Extract the text field\n",
    "    question = user_query['question']\n",
    "    # Extract keyword for filtering the results\n",
    "    course = user_query['course']\n",
    "    # Create the embedding of the user query\n",
    "    v_q = model.encode(question)\n",
    "    return elastic_search_knn('text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd4d2960-d233-47e8-96ee-2180ae9715a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the search function to use for evaluation\n",
    "def question_text_vector_knn(user_query):\n",
    "    # Extract the text field\n",
    "    question = user_query['question']\n",
    "    # Extract keyword for filtering the results\n",
    "    course = user_query['course']\n",
    "    # Create the embedding of the user query\n",
    "    v_q = model.encode(question)\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dee099-e541-4405-b3a2-5ca3a59d324c",
   "metadata": {},
   "source": [
    "### Calculate the HR and MRR metrics comparing the retrieved data with the ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b921643c-48f7-4973-9c8b-c585bba3e816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e11ad96dad54fdfb1a62e5b115a8519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.773071104387292, 'mrr': 0.6666810748505158}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the vector search only in questions of the FAQ\n",
    "evaluate(ground_truth, question_vector_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5cd409c-7fbb-4505-86a9-d539f8d93204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fd58c859ac4fe9ae4c6174c050841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8286146531229739, 'mrr': 0.7062315395144454}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the vector search only in text answer of the FAQ\n",
    "evaluate(ground_truth, text_vector_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbe1315c-7bca-42ec-9cf9-d9e7eef384fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ef24cec22341d58303551008dc0b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9172249837907932, 'mrr': 0.824306606152295}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the vector search in questions and answer of the FAQ\n",
    "evaluate(ground_truth, question_text_vector_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2ed40",
   "metadata": {},
   "source": [
    "## Evaluate hybrid search\n",
    "\n",
    "To evaluate the hybrid search we need to follow the following steps:\n",
    "- Create the embedding of the user query and query the data\n",
    "- Adjust the search query to use both vector and keyword search\n",
    "- Add the weight of each method in the query that will contribute to the total score\n",
    "- Calculate the HR and MRR metrics comparing the retrieved data with the ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "060d9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the ES query for hybrid search\n",
    "\n",
    "def elastic_search_hybrid(field, query, vector, course):\n",
    "    # This is the query for the vector search\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector, # This will recieve a vector of the user query\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5, # Here you can set up the weight the vector search will have in the results\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # This is the query for the keyword search\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query, # This will recieve the user query itself\n",
    "                    \"fields\": [\"question\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5, # Here you can set up the weight the keyword search will have in the results\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Here is the combination of the two search methods\n",
    "    search_query = {\n",
    "        \"knn\": knn_query,\n",
    "        \"query\": keyword_query,\n",
    "        \"size\": 5,   # This is the number of the returned documents\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"] # The fields that will be returned for each retrieved document \n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4213db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the hybrid search function to use for evaluation\n",
    "def question_text_search_hybrid(user_query):\n",
    "    # Extract the text field\n",
    "    question = user_query['question']\n",
    "    # Extract keyword for filtering the results\n",
    "    course = user_query['course']\n",
    "    # Create the embedding of the user query\n",
    "    v_q = model.encode(question)\n",
    "    return elastic_search_hybrid('question_text_vector', question ,v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0899eac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3052f696fb14a8b8f676a762d8e3649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9250054030689432, 'mrr': 0.8506231539514445}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the hybrid search in questions and answer of the FAQ\n",
    "evaluate(ground_truth, question_text_search_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d896e75",
   "metadata": {},
   "source": [
    "## Evaluate Reranking in Document Retrieval\n",
    "\n",
    "We used reranking process to re order the retrieved documents from the ES based on their relevance with the user query\n",
    "- Create the function to calculate the RRF\n",
    "- Retrieve the documents using hybrid search\n",
    "- From the retrieved document calculate the RRF score\n",
    "- Re order the retrieved documents based on the RRF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17ac4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the RRF metric\n",
    "def compute_rrf(rank, k=60):\n",
    "    return 1 / (k + rank)\n",
    "\n",
    "# Here we will retrieve 10 documents from the ES and reorder then using RRF\n",
    "def elastic_search_hybrid_rrf(field, query, vector, course, k=60):\n",
    "    # Vector Search\n",
    "    knn_query = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,  # Here we will retrieve 10 documents\n",
    "        \"num_candidates\": 10000,\n",
    "        \"boost\": 0.5,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Keyword search\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": 0.5,\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }    \n",
    "\n",
    "    # Here we are retrieving 10 documents from vector search\n",
    "    knn_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"knn\": knn_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "    # Here we are retrieving 10 documents from keyword search\n",
    "    keyword_results = es_client.search(\n",
    "        index=index_name, \n",
    "        body={\n",
    "            \"query\": keyword_query, \n",
    "            \"size\": 10\n",
    "        }\n",
    "    )['hits']['hits']\n",
    "\n",
    "    rrf_scores = {}\n",
    "    # Calculate RRF using vector search results\n",
    "    for rank, hit in enumerate(knn_results):\n",
    "        doc_id = hit['_id']\n",
    "        rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Adding keyword search result scores\n",
    "    for rank, hit in enumerate(keyword_results):\n",
    "        doc_id = hit['_id']\n",
    "        if doc_id in rrf_scores:\n",
    "            rrf_scores[doc_id] += compute_rrf(rank + 1, k)\n",
    "        else:\n",
    "            rrf_scores[doc_id] = compute_rrf(rank + 1, k)\n",
    "\n",
    "    # Sort RRF scores in descending order\n",
    "    reranked_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top 5 documents by the score\n",
    "    final_results = []\n",
    "    for doc_id, score in reranked_docs[:5]:\n",
    "        doc = es_client.get(index=index_name, id=doc_id)\n",
    "        final_results.append(doc['_source'])\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04d72eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_hybrid_rrf(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_hybrid_rrf('question_text_vector', question, v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "476fa3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d495ab9bcef4310af147d50602fc53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9520207477847418, 'mrr': 0.8745911677833017}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, question_text_hybrid_rrf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
