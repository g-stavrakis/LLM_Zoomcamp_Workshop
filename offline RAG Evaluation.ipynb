{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the RAG system\n",
    "\n",
    "To evaluate the LLM answer we will follow the below steps:\n",
    "- In the ground truth dataset we have a user question along with the actual answer of this question from the FAQ document\n",
    "- Pass each question of the ground truth dataset to the RAG sytem to get the LLM answer of that question\n",
    "- Create the embedding of the actual answer and the LLM Answer\n",
    "- Compute the cosine similarity and other metrics of the two answer to evaluate the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .envrc\n",
    "load_dotenv(\".envrc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the necessary documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FAQ records with their ids\n",
    "# Create the github url\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "# Request the json data\n",
    "docs_response = requests.get(docs_url)\n",
    "# Open the json data\n",
    "documents = docs_response.json()\n",
    "# Verify the first record\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with any id containing the full record\n",
    "doc_idx = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth dataset\n",
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the necessary documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector_questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the client \n",
    "es_client = Elasticsearch('http://localhost:9200') # This is the port created after running the docker file\n",
    "\n",
    "# Create the Schema of the Elastic Search Index\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"vector_questions\"\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e011aaa7181d40d29d1213c6179f4717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the selected model to create the embeddings\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# Create the embeddings for each record in our FAQ dataset\n",
    "for doc in tqdm(documents):\n",
    "    # Extract the text fields you want to embed\n",
    "    question_text = doc['question'] + ' ' + doc['text']\n",
    "    # Create the embedding for each text field\n",
    "    doc['question_text_vector'] = model.encode(question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34425da13714ac4af9457ea4a697abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the documents into the elastic search index\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retrieval function for the elastic search\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "# Create the retrieval part of rag with the optimal results\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to build the prompt\n",
    "def build_prompt(query, search_results):\n",
    "    # Create the prompt template\n",
    "    prompt_template = '''\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NONE.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    '''.strip()\n",
    "    \n",
    "    # Create the context from the search results\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    # Putting the context and query all together\n",
    "    prompt = prompt_template.format(question = query, context = context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the openai instance\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rag system function\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    # Search the knowledge base\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    # Prepare the prompt for the model\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    # Use the llm to get the response\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LLM answers based on ground truth questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 5 entries of the ground truth dataset\n",
    "sample = ground_truth[:5]\n",
    "# Initialize the answers\n",
    "answers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a09d2fe9ec4fdd94ac384ee711d906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the RAG system to generate the answers from the sample with gpt-4o\n",
    "for i, rec in enumerate(tqdm(sample)):\n",
    "    # Create a cache so in case tha the rag breaks we don't need to rerun it\n",
    "    if i in answers:\n",
    "        continue\n",
    "    # Generate the LLM answer\n",
    "    answer_llm = rag(rec)\n",
    "    # Extract the document Id from the ground truth\n",
    "    doc_id = rec['document']\n",
    "    # Extract the original record from the ground truth\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    # Save the answer from the ground truth record\n",
    "    answer_orig = original_doc['text']\n",
    "    # Save the answers in 1 entry\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up for the course using the link ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0                                               NONE   \n",
       "1  You can sign up for the course using the link ...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3                                               NONE   \n",
       "4                                               NONE   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results as a Dataframe\n",
    "pd.DataFrame(answers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the answers\n",
    "answers_35 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d269a7f5d44cc78bd5582062fca7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the RAG system to generate the answers from the sample with Gpt 3.5 turbo\n",
    "for i, rec in enumerate(tqdm(sample)):\n",
    "    # Create a cache so in case tha the rag breaks we don't need to rerun it\n",
    "    if i in answers_35:\n",
    "        continue\n",
    "    # Generate the LLM answer\n",
    "    answer_llm = rag(rec, model='gpt-3.5-turbo')\n",
    "    # Extract the document Id from the ground truth\n",
    "    doc_id = rec['document']\n",
    "    # Extract the original record from the ground truth\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    # Save the answer from the ground truth record\n",
    "    answer_orig = original_doc['text']\n",
    "    # Save the answers in 1 entry\n",
    "    answers_35[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can structure your questions and answers f...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0                                               NONE   \n",
       "1                                               NONE   \n",
       "2                                               NONE   \n",
       "3                                               NONE   \n",
       "4  You can structure your questions and answers f...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results as a Dataframe\n",
    "pd.DataFrame(answers_35.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Where can I sign up for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 1: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Can you provide a link to sign up?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 2: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Is there an FAQ for this Machine Learning course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 3: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Does this course have a GitHub repository for the sign-up link?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 4: {'answer_llm': 'You can structure your questions and answers for the course in any language, but it is not advisable to do the course in languages other than Python due to specific requirements and peer review considerations.',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'How can I structure my questions and answers for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "# Download the full results with gpt-4o\n",
    "!wget r'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/04-monitoring/data/results-gpt4o.csv'\n",
    "# Download the full results with gpt-3.5\n",
    "!wget r'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/04-monitoring/data/results-gpt35.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the llm and actual answers from gpt4o\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt4o.csv'\n",
    "results_gpt4o_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_results_gpt4o = pd.read_csv(results_gpt4o_url)\n",
    "results_gpt4o = df_results_gpt4o.to_dict(orient='records')\n",
    "\n",
    "# Load the llm and actual answers from gpt35\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt35.csv'\n",
    "results_gpt35_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_results_gpt35 = pd.read_csv(results_gpt35_url)\n",
    "results_gpt35 = df_results_gpt35.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Yes, sessions are recorded, so you won’t miss anything if you miss a session. You can view the recordings later. Additionally, you can ask questions for office hours in advance or on Slack, and they will be addressed during the live stream or in the Slack channel.', 'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.', 'document': '5170565b', 'question': 'Are sessions recorded if I miss one?', 'course': 'machine-learning-zoomcamp'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7962799"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the cosine similarity for one record\n",
    "record = results_gpt4o[10]\n",
    "# Extract the two answers to compare\n",
    "answer_llm = record['answer_llm']\n",
    "answer_orig = record['answer_orig']\n",
    "# Create the embeddings for the two answers\n",
    "v_llm = model.encode(answer_llm)\n",
    "v_orig = model.encode(answer_orig)\n",
    "# Calculate the cosine similarity\n",
    "print(record)\n",
    "v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to calculate cosine similarity\n",
    "def compute_similarity(record):\n",
    "    # Extract the two answers to compare\n",
    "    answer_llm = record['answer_llm']\n",
    "    answer_orig = record['answer_orig']\n",
    "    # Create the embeddings for the two answers\n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    # Calculate the cosine similarity\n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarities for all records of the gpt4oresults\n",
    "similarities_4o = [compute_similarity(record) for record in results_gpt4o]\n",
    "# Save the similarities in the results\n",
    "df_results_gpt4o['cosine'] = similarities_4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.679129\n",
       "std         0.217995\n",
       "min        -0.153425\n",
       "25%         0.591460\n",
       "50%         0.734788\n",
       "75%         0.835390\n",
       "max         0.995338\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculare the descriptive statistics for the similarities\n",
    "df_results_gpt4o['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarities for all records of the gpt4oresults\n",
    "similarities_35 = [compute_similarity(record) for record in results_gpt35]\n",
    "# Save the similarities in the results\n",
    "df_results_gpt35['cosine'] = similarities_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.657599\n",
       "std         0.226062\n",
       "min        -0.168921\n",
       "25%         0.546504\n",
       "50%         0.714783\n",
       "75%         0.817262\n",
       "max         1.000000\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculare the descriptive statistics for the similarities\n",
    "df_results_gpt35['cosine'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMZoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
