{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using similarity metrics\n",
    "\n",
    "To evaluate the LLM answer we will follow the below steps:\n",
    "- In the ground truth dataset we have a user question along with the actual answer of this question from the FAQ document\n",
    "- Pass each question of the ground truth dataset to the RAG sytem to get the LLM answer of that question\n",
    "- Create the embedding of the actual answer and the LLM Answer\n",
    "- Compute the cosine similarity and other metrics of the two answer to evaluate the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .envrc\n",
    "load_dotenv(\".envrc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the necessary documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the FAQ records with their ids\n",
    "# Create the github url\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "# Request the json data\n",
    "docs_response = requests.get(docs_url)\n",
    "# Open the json data\n",
    "documents = docs_response.json()\n",
    "# Verify the first record\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with any id containing the full record\n",
    "doc_idx = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth dataset\n",
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index the necessary documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'vector_questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the client \n",
    "es_client = Elasticsearch('http://localhost:9200') # This is the port created after running the docker file\n",
    "\n",
    "# Create the Schema of the Elastic Search Index\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,            # Here we are using the dimensionality of the embedding we want to store \n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Provide the name of the index\n",
    "index_name = \"vector_questions\"\n",
    "# Create the elastic search index\n",
    "response = es_client.indices.create(index=index_name, body=index_settings)\n",
    "# Verify that elastic search is created\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgestavrakis/opt/anaconda3/envs/LLMZoomcamp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e011aaa7181d40d29d1213c6179f4717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the selected model to create the embeddings\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "# Create the embeddings for each record in our FAQ dataset\n",
    "for doc in tqdm(documents):\n",
    "    # Extract the text fields you want to embed\n",
    "    question_text = doc['question'] + ' ' + doc['text']\n",
    "    # Create the embedding for each text field\n",
    "    doc['question_text_vector'] = model.encode(question_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34425da13714ac4af9457ea4a697abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the documents into the elastic search index\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index = index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retrieval function for the elastic search\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "# Create the retrieval part of rag with the optimal results\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to build the prompt\n",
    "def build_prompt(query, search_results):\n",
    "    # Create the prompt template\n",
    "    prompt_template = '''\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NONE.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    '''.strip()\n",
    "    \n",
    "    # Create the context from the search results\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    # Putting the context and query all together\n",
    "    prompt = prompt_template.format(question = query, context = context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the openai instance\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rag system function\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    # Search the knowledge base\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    # Prepare the prompt for the model\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    # Use the llm to get the response\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LLM answers based on ground truth questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 5 entries of the ground truth dataset\n",
    "sample = ground_truth[:5]\n",
    "# Initialize the answers\n",
    "answers = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a09d2fe9ec4fdd94ac384ee711d906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the RAG system to generate the answers from the sample with gpt-4o\n",
    "for i, rec in enumerate(tqdm(sample)):\n",
    "    # Create a cache so in case tha the rag breaks we don't need to rerun it\n",
    "    if i in answers:\n",
    "        continue\n",
    "    # Generate the LLM answer\n",
    "    answer_llm = rag(rec)\n",
    "    # Extract the document Id from the ground truth\n",
    "    doc_id = rec['document']\n",
    "    # Extract the original record from the ground truth\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    # Save the answer from the ground truth record\n",
    "    answer_orig = original_doc['text']\n",
    "    # Save the answers in 1 entry\n",
    "    answers[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up for the course using the link ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0                                               NONE   \n",
       "1  You can sign up for the course using the link ...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3                                               NONE   \n",
       "4                                               NONE   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results as a Dataframe\n",
    "pd.DataFrame(answers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the answers\n",
    "answers_35 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d269a7f5d44cc78bd5582062fca7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the RAG system to generate the answers from the sample with Gpt 3.5 turbo\n",
    "for i, rec in enumerate(tqdm(sample)):\n",
    "    # Create a cache so in case tha the rag breaks we don't need to rerun it\n",
    "    if i in answers_35:\n",
    "        continue\n",
    "    # Generate the LLM answer\n",
    "    answer_llm = rag(rec, model='gpt-3.5-turbo')\n",
    "    # Extract the document Id from the ground truth\n",
    "    doc_id = rec['document']\n",
    "    # Extract the original record from the ground truth\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    # Save the answer from the ground truth record\n",
    "    answer_orig = original_doc['text']\n",
    "    # Save the answers in 1 entry\n",
    "    answers_35[i] = {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_orig': answer_orig,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NONE</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can structure your questions and answers f...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0                                               NONE   \n",
       "1                                               NONE   \n",
       "2                                               NONE   \n",
       "3                                               NONE   \n",
       "4  You can structure your questions and answers f...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results as a Dataframe\n",
    "pd.DataFrame(answers_35.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Where can I sign up for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 1: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Can you provide a link to sign up?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 2: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Is there an FAQ for this Machine Learning course?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 3: {'answer_llm': 'NONE',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'Does this course have a GitHub repository for the sign-up link?',\n",
       "  'course': 'machine-learning-zoomcamp'},\n",
       " 4: {'answer_llm': 'You can structure your questions and answers for the course in any language, but it is not advisable to do the course in languages other than Python due to specific requirements and peer review considerations.',\n",
       "  'answer_orig': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       "  'document': '0227b872',\n",
       "  'question': 'How can I structure my questions and answers for the course?',\n",
       "  'course': 'machine-learning-zoomcamp'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "# Download the full results with gpt-4o\n",
    "!wget r'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/04-monitoring/data/results-gpt4o.csv'\n",
    "# Download the full results with gpt-3.5\n",
    "!wget r'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/refs/heads/main/04-monitoring/data/results-gpt35.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the llm and actual answers from gpt4o\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt4o.csv'\n",
    "results_gpt4o_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_results_gpt4o = pd.read_csv(results_gpt4o_url)\n",
    "results_gpt4o = df_results_gpt4o.to_dict(orient='records')\n",
    "\n",
    "# Load the llm and actual answers from gpt35\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt35.csv'\n",
    "results_gpt35_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_results_gpt35 = pd.read_csv(results_gpt35_url)\n",
    "results_gpt35 = df_results_gpt35.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_llm': 'Yes, sessions are recorded, so you won’t miss anything if you miss a session. You can view the recordings later. Additionally, you can ask questions for office hours in advance or on Slack, and they will be addressed during the live stream or in the Slack channel.', 'answer_orig': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.', 'document': '5170565b', 'question': 'Are sessions recorded if I miss one?', 'course': 'machine-learning-zoomcamp'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7962799"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the cosine similarity for one record\n",
    "record = results_gpt4o[10]\n",
    "# Extract the two answers to compare\n",
    "answer_llm = record['answer_llm']\n",
    "answer_orig = record['answer_orig']\n",
    "# Create the embeddings for the two answers\n",
    "v_llm = model.encode(answer_llm)\n",
    "v_orig = model.encode(answer_orig)\n",
    "# Calculate the cosine similarity\n",
    "print(record)\n",
    "v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to calculate cosine similarity\n",
    "def compute_similarity(record):\n",
    "    # Extract the two answers to compare\n",
    "    answer_llm = record['answer_llm']\n",
    "    answer_orig = record['answer_orig']\n",
    "    # Create the embeddings for the two answers\n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    # Calculate the cosine similarity\n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarities for all records of the gpt4oresults\n",
    "similarities_4o = [compute_similarity(record) for record in results_gpt4o]\n",
    "# Save the similarities in the results\n",
    "df_results_gpt4o['cosine'] = similarities_4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.679129\n",
       "std         0.217995\n",
       "min        -0.153425\n",
       "25%         0.591460\n",
       "50%         0.734788\n",
       "75%         0.835390\n",
       "max         0.995338\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculare the descriptive statistics for the similarities\n",
    "df_results_gpt4o['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarities for all records of the gpt4oresults\n",
    "similarities_35 = [compute_similarity(record) for record in results_gpt35]\n",
    "# Save the similarities in the results\n",
    "df_results_gpt35['cosine'] = similarities_35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.657599\n",
       "std         0.226062\n",
       "min        -0.168921\n",
       "25%         0.546504\n",
       "50%         0.714783\n",
       "75%         0.817262\n",
       "max         1.000000\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculare the descriptive statistics for the similarities\n",
    "df_results_gpt35['cosine'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using LLM-as-a-Judge\n",
    "\n",
    "To evaluate the LLM answer we will follow the below steps:\n",
    "- In the ground truth dataset we have a user question along with the actual answer of this question from the FAQ document\n",
    "- Pass each question of the ground truth dataset to the RAG sytem to get the LLM answer of that question\n",
    "- Offline Evaluation -> Create a prompt for an LLM to evaluate the generated and original answer and see if it's relevant based also on the generated answer \n",
    "- Online Evaluation -> Create a prompt for an LLM to evaluate the generated answer and see if it's relevant based also on the generated answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the two new prompts\n",
    "\n",
    "# Offline prompt template\n",
    "offline_prompt_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_orig}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# Online prompt template\n",
    "online_prompt_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>The syntax for using `precision_recall_fscore_...</td>\n",
       "      <td>Scikit-learn offers another way: precision_rec...</td>\n",
       "      <td>403bbdd8</td>\n",
       "      <td>What is the syntax for using precision_recall_...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.881816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>To avoid pickle errors when using waitress, yo...</td>\n",
       "      <td>When running a docker container with waitress ...</td>\n",
       "      <td>236864c2</td>\n",
       "      <td>How should I modify my scripts to avoid pickle...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.742705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>To launch a container image in interactive mod...</td>\n",
       "      <td>Launch the container image in interactive mode...</td>\n",
       "      <td>63a81b57</td>\n",
       "      <td>What command launches a container image in int...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.841399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>Yes, you can make a pull request for homework ...</td>\n",
       "      <td>Pytorch is also a deep learning framework that...</td>\n",
       "      <td>c4ff26e5</td>\n",
       "      <td>Can we make a pull request for homework soluti...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.701560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>The pip version error in this week's serverles...</td>\n",
       "      <td>When running docker build -t dino-dragon-model...</td>\n",
       "      <td>42c09143</td>\n",
       "      <td>What might be the cause of the pip version err...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.303531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "726   The syntax for using `precision_recall_fscore_...   \n",
       "1662  To avoid pickle errors when using waitress, yo...   \n",
       "834   To launch a container image in interactive mod...   \n",
       "1234  Yes, you can make a pull request for homework ...   \n",
       "1323  The pip version error in this week's serverles...   \n",
       "\n",
       "                                            answer_orig  document  \\\n",
       "726   Scikit-learn offers another way: precision_rec...  403bbdd8   \n",
       "1662  When running a docker container with waitress ...  236864c2   \n",
       "834   Launch the container image in interactive mode...  63a81b57   \n",
       "1234  Pytorch is also a deep learning framework that...  c4ff26e5   \n",
       "1323  When running docker build -t dino-dragon-model...  42c09143   \n",
       "\n",
       "                                               question  \\\n",
       "726   What is the syntax for using precision_recall_...   \n",
       "1662  How should I modify my scripts to avoid pickle...   \n",
       "834   What command launches a container image in int...   \n",
       "1234  Can we make a pull request for homework soluti...   \n",
       "1323  What might be the cause of the pip version err...   \n",
       "\n",
       "                         course    cosine  \n",
       "726   machine-learning-zoomcamp  0.881816  \n",
       "1662  machine-learning-zoomcamp  0.742705  \n",
       "834   machine-learning-zoomcamp  0.841399  \n",
       "1234  machine-learning-zoomcamp  0.701560  \n",
       "1323  machine-learning-zoomcamp  0.303531  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract a sample of the results\n",
    "df_sample = df_results_gpt4o.sample(n=50, random_state=1)\n",
    "# Preview the sample\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c42ee34f7342fdac6048fc2bc7e82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the offline evaluation process\n",
    "offline_evaluations = []\n",
    "\n",
    "# Convert the samples as a dictionary\n",
    "samples = df_sample.to_dict(orient='records')\n",
    "# For each record \n",
    "for record in tqdm(samples):\n",
    "    # Create the offline prompt\n",
    "    prompt = offline_prompt_template.format(**record)\n",
    "    # Ask the llm to be the judge\n",
    "    answer = llm(prompt, model='gpt-4o-mini')\n",
    "    # Parse the response and append it into a list of results\n",
    "    json_eval = json.loads(answer)\n",
    "    offline_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RELEVANT           39\n",
       "PARTLY_RELEVANT     8\n",
       "NON_RELEVANT        3\n",
       "Name: Relevance, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine how manre relevand documents we have\n",
    "df_offline_evaluations = pd.DataFrame(offline_evaluations)\n",
    "df_offline_evaluations.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 11, 41]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_llm': \"The pip version error in this week's serverless deep learning section might be due to a version conflict or mismatch with dependencies, particularly with Scikit-Learn. Based on similar FAQ entries, here's a potential cause:\\n\\nWhen running certain commands (e.g., `pipenv shell` followed by `pipenv run gunicorn --bind 0.0.0.0:9696 predict:app`), you might encounter warnings about version clashes, such as trying to unpickle an estimator from different Scikit-Learn versions. This indicates that the versions of Scikit-Learn used during model training and deployment are inconsistent.\\n\\n### Potential Solutions:\\n1. **Ensure Consistent Scikit-Learn Versions:** Ensure that the virtual environment uses the same version of Scikit-Learn that was used during the model training. For example, if the model was trained using Scikit-Learn version 1.1.1, the same version should be installed in the deployment environment.\\n2. **Correct Package Installation Command:** If you face errors while installing specific versions of Scikit-Learn (e.g., `pipenv install sklearn==1.0.2`), use the full package name: `pipenv install scikit-learn==1.0.2`. For homework or specific instructions, ensure the correct version is installed, such as `pipenv install scikit-learn==1.3.1`.\\n\\nIf these steps do not resolve the problem, you might also need to address dependency resolution issues by using `pipenv lock` to fix the dependency files.\",\n",
       " 'answer_orig': 'When running docker build -t dino-dragon-model it returns the above error\\nThe most common source of this error in this week is because Alex video shows a version of the wheel with python 8, we need to find a wheel with the version that we are working on. In this case python 9. Another common error is to copy the link, this will also produce the same error, we need to download the raw format:\\nhttps://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp39-cp39-linux_x86_64.whl\\nPastor Soto',\n",
       " 'document': '42c09143',\n",
       " 'question': \"What might be the cause of the pip version error in this week's serverless deep learning section?\",\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'cosine': 0.30353105068206787}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine one non-relevant answer\n",
    "print(list(df_offline_evaluations[df_offline_evaluations['Relevance']=='NON_RELEVANT'].index))\n",
    "# See the correspoding record\n",
    "samples[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d228f3e94d94248819a53731b26de24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the offline evaluation process\n",
    "online_evaluations = []\n",
    "\n",
    "# Convert the samples as a dictionary\n",
    "samples = df_sample.to_dict(orient='records')\n",
    "# For each record \n",
    "for record in tqdm(samples):\n",
    "    # Create the offline prompt\n",
    "    prompt = online_prompt_template.format(**record)\n",
    "    # Ask the llm to be the judge\n",
    "    answer = llm(prompt, model='gpt-4o-mini')\n",
    "    # Parse the response and append it into a list of results\n",
    "    json_eval = json.loads(answer)\n",
    "    online_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RELEVANT           45\n",
       "PARTLY_RELEVANT     5\n",
       "Name: Relevance, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_online_evaluations = pd.DataFrame(online_evaluations)\n",
    "df_online_evaluations.Relevance.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMZoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
